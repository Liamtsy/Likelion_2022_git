{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "272503b3",
   "metadata": {},
   "source": [
    "### 크롤링?\n",
    "\n",
    "웹 스크래핑, 웹스파이더링, 웹크롤링이라고 불리는 이 기술은 웹페이지에 널려져있는 데이터들을 프로그래밍적으로 추출하는 행위를 말한다.\n",
    "\n",
    "쉽게 이해하자면 웹페이지상에서 데이터를 긁어와서 가져오는 것이다. 아래 그림을 보면 확실하게 이해가 된다.\n",
    " \n",
    " \n",
    "크롤링의 활용 예들 (웹페이지에서 원하는 정보를 가져올때)\n",
    " \n",
    "\n",
    "1) 네이버뉴스, 다음뉴스 등등 여러가지 뉴스웹사이트에서 나오는 정보들을 일괄적으로 자신이 원하는 입맛에 맞춘 데이터들만 뽑아내기\n",
    "\n",
    "\n",
    "2) 멜론 사이트에서 현재 음악차트 순위를 가져와 엑셀파일로 만들기\n",
    "\n",
    "\n",
    "3) 여러 쇼핑몰사이트에서 내가원하는 키워드 뽑기\n",
    "\n",
    "python -> 비단뱀의 영어 이름\n",
    "crawling -> 파충류가 기어다닌다는 의미\n",
    "crawler의 의미 -> 기는 것, 도마뱀\n",
    "\n",
    "web crawler 을 이용해서 웹에서 데이터를 가져오는 행위 -> crawling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69cdba7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'requests' from 'C:\\\\Users\\\\system1\\\\anaconda3\\\\lib\\\\site-packages\\\\requests\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "## 모듈 설치:\n",
    "## 다른 사람들이 만들어놓은  crawling 기술을 가져오도록 하겠다.\n",
    "## pip install requests ## 파이썬 크롤링에서 필요한 패키지 \n",
    "\n",
    "## 파이썬의 함수: 자주 쓰는 코드들을 묶어놓고 간단하게 사용할 수 있도록 해주는 역할 -> 반복적인 활동을 줄여준다.\n",
    "## 파이썬의 모듈: 기능을 구성하는 함수를 하나로 묶어서 만든 그룹, 즉 함수 여러개가 모여서 모듈이 된다. ## 클래스와 변수가 들어가도 된다.\n",
    "\n",
    "## requests 사용법\n",
    "\"\"\"\n",
    "1. requests 모듈을 실행\n",
    "2. get 함수를 꺼내기 -> 응답값을 가져온다. => return 응답값 - \n",
    "3. 요청을 보내기\n",
    "\"\"\"\n",
    "\n",
    "import requests ##모듈을 import 해온다.\n",
    "## print(requests)## 위치가 보임\n",
    "\n",
    "## 우리는 requests 내에 있는 get 함수를 사용하려고 함. get 함수는 url을 필요로 한다.\n",
    "## requests.get(url)\n",
    "## get 요청을 보내는 기능이다.\n",
    "\"\"\"\n",
    "정확히는 put, get, post, delete 등의 요청을 보내는 기능이다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98c3735f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://www.daum.net\"\n",
    "#print(requests.get(url)) ## <Response [200]> -> 200이 나오면 성공을 의미한다.\n",
    "## 이를 response에 저장해보도록 하겠다.\n",
    "response = requests.get(url)\n",
    "#print(response.text) ## html 코드를 가져왔다고 할 수 있다.\n",
    "## html을 앞에서 배워본적이 있으니, 여기서 이제 html 테그들을 이해할 수 있겠지? \n",
    "## 테그를 통해서 자신이 원하는 정보들도 가져올 수 있다.\n",
    "\"\"\"\n",
    "#print(response.url) ## 주소를 가져온다.\n",
    "#print(response.content) ## contents 를 가져온다.\n",
    "#print(response.encoding) ## encoding 방식를 가져온다.\n",
    "#print(response.headers) ## header를 가져온다.\n",
    "#print(response.json) ## json을 가져온다.\n",
    "#print(response.links) ## 링크들을 가져온다.\n",
    "#print(response.ok) ## 요청 허용 여부를 가져온다.\n",
    "## https://docs.python-requests.org/en/master/api/#requests.Response\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f92c631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Daum</title>\n",
      "Daum\n",
      "None\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "## 전체 코드\n",
    "import requests\n",
    "from bs4 import BeautifulSoup ## 모듈 이름이 아닌 한 기능의 이름이 BeutifulSoup이다.\n",
    "## 모듈 어디서 가져오는지를 먼저 적어줘야 한다. bs4모듈을 사용할 것이다.\n",
    "url = \"http://www.daum.net\"\n",
    "response = requests.get(url)\n",
    "#print(type(response.text))\n",
    "## type -> 괄호 내 타입을 말해준다.\n",
    "#print(BeautifulSoup(response.text, 'html.parser'))\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "## response.text라는 문자열을 다 떼서, beautifulsoup라는 통에 다 정리해놓은 형태이다.\n",
    "## request.text 를 데이터 자료로 사용\n",
    "## parsing -> 문자열을 의미있는 값으로 분류, 변경 -> parsing을 도와주는 도구: parser\n",
    "print(soup.title)\n",
    "#print(response.text[:500])\n",
    "print(soup.title.string)\n",
    "print(soup.span) ## spandtag 가져오기 -> 맨 위만 가져온다.\n",
    "print(soup.findAll('span')) ## span tag 모두를 가져온다.\n",
    "## 위 둘이 동일하다는 것을 알 수 있다.\n",
    "## findAll 내에 span 을 넣으면, \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c62af2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"https://www.enable-javascript.com/ko/\"> ë¸ë¼ì°ì ìì ìë°ì¤í¬ë¦½í¸ë¥¼ íì±ííë ë°©ë²</a>]\n"
     ]
    }
   ],
   "source": [
    "## 예시 :실시간 검색어 -> 이제는 안되긴 해요, 실시간 검색어가 막혔어요. 강의에서 제공한 코드입니다.\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"https://www.daum.net/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#print(soup)\n",
    "\"\"\"\n",
    "file = open(\"daum.html\",\"w\", encoding = \"UTF-8\")\n",
    "file.write(response.text)\n",
    "file.close()\n",
    "## 자신의 워크 스페이스에 daum.html이 생기게 된다.\n",
    "## 여기서 공통점을 찾아서 실시간 검색어를 찾아오도록 한다.\n",
    "## a 테그에 link_favorsch 클래스를 가지고 있다.\n",
    "print(soup.title)\n",
    "print(soup.title.string)\n",
    "print(soup.span)\n",
    "print(soup.findAll('span'))\n",
    "\"\"\"\n",
    "###html 문서에서 모든 a 태그를 가져오는 콛,\n",
    "print(soup.findAll('a'))\n",
    "#print(soup.findAll('a',\"link_favorsch\")) ## a tag 내에 감겨있는 테그가 함께 출력된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1e8c3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022년 02월 16일의 실시간 검색어 순위입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 위의 경우는 한글이 깨진다는 문제가 있다. 아래와 같은 방법을 사용한다.\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "url = \"https://www.daum.net/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "## 파싱: decode를 통해서 한글이 깨지는 현상을 해결\n",
    "soup = BeautifulSoup(response.content.decode('UTF-8', 'replace'), 'html.parser')\n",
    "soup.findAll('title')\n",
    "\n",
    "results = soup.findAll(\"a\",\"link_favorsch\")\n",
    "\n",
    "\"\"\"\n",
    "for result in results:\n",
    "    print(result,\"\\n\")\n",
    "\"\"\"\n",
    "print(datetime.today().strftime(\"%Y년 %m월 %d일의 실시간 검색어 순위입니다.\\n\"))\n",
    "for result in results:\n",
    "    print(rank,\"위 : \",result.get_text(),\"\\n\")\n",
    "    rank += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9c5f263e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"ko\">\n",
      "<head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <!-- [D] Internet Explorer Document Mode 최신으로 설정 -->\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "    <title>페이지를 찾을 수 없습니다. : 빅데이터포털</title>\n",
      "    <style type=\"text/css\">\n",
      "        /* NHN Technology Services MJH 151228 */\n",
      "        /* Common */\n",
      "        html, body { height: 100%; }\n",
      "        body, p, h1, h2, h3, h4, h5, h6, ul, ol, li, dl, dt, dd, table, th, td, form, fieldset, legend, input, textarea, button, select { margin: 0; padding: 0; }\n",
      "        body{ background: #3a3d40; font-family: '나눔고딕',NanumGothic,'돋움',Dotum,Helvetica,sans-serif; font-size: 16px; color: #404d5d; letter-spacing: -1px; }\n",
      "        a { color: inherit; text-decoration: none; }\n",
      "        .blind { overflow: hidden; position: absolute; clip: rect(0 0 0 0); width: 1px; height: 1px; margin: -1px; }\n",
      "        .sp,\n",
      "        .sp_before:before { background-image: url(https://ssl.pstatic.net/static.datalab/202201130701/img/sp_error.png); background-repeat: no-repeat; }\n",
      "        .wrap { min-width: 1200px; }\n",
      "        .container { background: #fff; }\n",
      "        .content_error { min-height: 910px; padding-top: 240px; text-align: center; box-sizing: border-box; }\n",
      "        .error_title { font-weight: normal; font-size: 33px; }\n",
      "        .error_title:before { display:block; width: 40px; height: 40px; margin: 0 auto 26px; background-position: 0 0; content: ''; }\n",
      "        .error_title:after { display: block; width: 50px; height: 2px; margin: 25px auto 0; background: #d5dce2; content: ''; }\n",
      "        .error_desc { margin-top: 31px; line-height: 30px; }\n",
      "        .error_desc .link { color: #4a8fda; text-decoration: underline; }\n",
      "        .error_prev { display: inline-block; margin-top: 70px; color: #777; }\n",
      "        .error_prev:before { display:inline-block; width: 18px; height: 17px; margin-right: 7px; background-position: -44px 0 ; vertical-align: -3px; content: ''; }\n",
      "        .footer { width: 100%; height: 120px; background: #3a3d40; color: #999; }\n",
      "        .footer a { color: inherit; }\n",
      "        .footer .footer_inner { width: 1090px; margin: 0 auto; padding-top: 40px; text-align: center; }\n",
      "        .footer .footer_info { font-size: 12px; }\n",
      "        .footer .footer_info strong { color: #ccc; }\n",
      "        .footer .footer_info a:hover { text-decoration: underline; }\n",
      "        .footer .footer_info a + a:before { display: inline-block; width: 1px; height: 11px; margin: 0 6px; background: #4d4f52; vertical-align: -2px; content: ''; }\n",
      "        .footer .footer_copyright { margin-top: 19px; font-family: Verdana; font-size: 9px; letter-spacing: 0; }\n",
      "        .footer .footer_copyright strong a:hover { color: #ccc; text-decoration: underline; }\n",
      "        .footer .footer_logo { height: 11px; width: 62px; background-position: 0px -44px; display: inline-block; margin-right: 10px; vertical-align: -2px; }\n",
      "        .footer .copyright { font-family: Tahoma; font-size: 10px; }\n",
      "    </style>\n",
      "</head>\n",
      "\n",
      "<body>\n",
      "<div id=\"wrap\" class=\"wrap\">\n",
      "\n",
      "    <!-- container -->\n",
      "    <div id=\"container\" class=\"container\" role=\"main\">\n",
      "        <!-- content -->\n",
      "        <div id=\"content\" class=\"content_error\">\n",
      "            <h1 class=\"error_title sp_before\">오류로 데이터 표시를 할 수 없습니다.</h1>\n",
      "            <p class=\"error_desc\">\n",
      "                이용에 불편을 드려서 죄송합니다.\n",
      "                궁금한 사항은 <a href=\"https://help.naver.com/support/service/main.nhn?serviceNo=14493\" target=\"_blank\" class=\"link\">고객센터</a>에 문의해주시면 안내드리겠습니다.<br>\n",
      "                감사합니다.\n",
      "            </p>\n",
      "            <a href=\"javascript:history.back()\" class=\"error_prev sp_before\">이전 페이지로</a>\n",
      "        </div>\n",
      "        <!-- //content -->\n",
      "    </div>\n",
      "    <!-- //container -->\n",
      "\n",
      "    <!-- footer -->\n",
      "    <div id=\"footer\" class=\"footer\">\n",
      "        <div class=\"footer_inner\">\n",
      "            <div class=\"footer_info\">\n",
      "                <a href=\"https://policy.naver.com/rules/service.html\" target=\"_blank\">이용약관</a>\n",
      "                <a href=\"https://policy.naver.com/rules/privacy.html\" target=\"_blank\"><strong>개인정보취급방침</strong></a>\n",
      "                <a href=\"https://policy.naver.com/rules/disclaimer.html\" target=\"_blank\">책임의 한계와 법적고지</a>\n",
      "                <a href=\"https://help.naver.com/support/service/main.nhn?serviceNo=14493\" target=\"_blank\">고객센터</a>\n",
      "            </div>\n",
      "            <div class=\"footer_copyright\">\n",
      "                <a href=\"https://www.naver.com/\" target=\"_blank\" class=\"footer_logo sp\"><span class=\"blind\">NAVER</span></a>\n",
      "                <em class=\"copyright\">Copyright ©</em>\n",
      "                <strong><a href=\"https://www.navercorp.com/ko/index.nhn\" target=\"_blank\">NAVER Corp.</a></strong> All Rights Reserved.\n",
      "            </div>\n",
      "        </div>\n",
      "    </div>\n",
      "    <!-- //footer -->\n",
      "\n",
      "</div>\n",
      "\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "2022년 02월 16일의 실시간 검색어 순위입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 실시간 검색어 예시- 이쁘게 수정\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}\n",
    "url = \"https://datalab.naver.com/keyword/realtimeList.naver?age=20s\"\n",
    "response = requests.get(url,headers=headers)\n",
    "soup = BeautifulSoup(response.content.decode('UTF-8', 'replace'), 'html.parser')\n",
    "rank = 1\n",
    "# span - item_title\n",
    "results = soup.findAll('span','item_title')\n",
    "\n",
    "print(response.text)\n",
    "\n",
    "search_rank_file = open(\"rankresult.txt\",\"a\")\n",
    "\n",
    "print(datetime.today().strftime(\"%Y년 %m월 %d일의 실시간 검색어 순위입니다.\\n\"))\n",
    "\n",
    "for result in results:\n",
    "    search_rank_file.write(str(rank)+\"위:\"+result.get_text()+\"\\n\")\n",
    "    print(rank,\"위 : \",result.get_text(),\"\\n\")\n",
    "    rank += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02017369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 뉴스:유학대학온라인비교과프로그램<인문학을위한융합교육>성료\n",
      "2번 뉴스:올해삼성휴먼테크논문대상에서6편수상및교수당최다수상학과(에너지과학과)선정\n",
      "3번 뉴스:의학과안지인교수,조현병환자치료를위한새로운유전적원인과작동원리밝혀내\n",
      "4번 뉴스:본교,국토교통부그린리모델링지역거점플랫폼수도권대표기관으로선정\n",
      "5번 뉴스:신소재공학과홍성인박사,가천대학교물리학과조교수임용\n",
      "6번 뉴스:통계분석학회P-SAT,2021년빅콘테스트대상및11건수상\n",
      "7번 뉴스:SKKGSB,영국파이낸셜타임스(FT)세계주간MBA평가11년연속한국1위\n",
      "8번 뉴스:동아시아학술원이영호교수,한국고전번역학회회장선출\n",
      "9번 뉴스:대학최초로졸업식에서블록체인기술기반NFT상장수여\n",
      "10번 뉴스:물리학과졸업생박혜진박사,인하대물리학과조교수임용\n"
     ]
    }
   ],
   "source": [
    "## 예시 - 성대신문 첫 페이지 기사 가져오기\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "url = 'https://www.skku.edu/skku/campus/skk_comm/news.do'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "title = soup.find_all(\"div\", class_='news_listCont')\n",
    "titles = []\n",
    "\n",
    "for x in title:\n",
    "    global titles\n",
    "    titles.append(re.sub(r\"[\\n\\t\\s]*\", \"\", x.find(\"a\").get_text()))\n",
    "titles ## 리스트 형태로 저장\n",
    "\n",
    "for i in range(0, len(titles)):\n",
    "    print(str(i+1)+\"번 뉴스:\"+ titles[i])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
