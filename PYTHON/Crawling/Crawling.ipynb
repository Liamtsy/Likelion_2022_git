{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5cc50631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\r\n",
      "<html lang=\"ko\">\r\n",
      "  <head>\r\n",
      "    <meta charset=\"utf-8\">\r\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\r\n",
      "    <meta name=\"description\" content=\"지금 떠오르는 이슈 키워드를 확인해보세요\">\r\n",
      "\t<meta name=\"keywords\" content=\"이슈 키워드, 실시간 검색어, tisword, 티스워드\">\r\n",
      "\t<meta property=\"og:type\" content=\"website\">\r\n",
      "\t<meta property=\"og:title\" content=\"실시간 이슈 검색어 - 티스워드\">\r\n",
      "\t<meta property=\"og:url\" content=\"https://tisword.com/realtime/\">\r\n",
      "\t<meta property=\"og:description\" content=\"지금 떠오르는 이슈 \n",
      "<class 'bs4.BeautifulSoup'>\n",
      "2022년 05월 04일의 실시간 검색어 순위입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#실검 크롤링, 근데 강의 업뎃 안돼서 실검 불러오는게 안됨;\n",
    "import requests # 남이 만들어놓은 requests라는 모듈을 사용함. 안에 무슨 함수들이 있을까?\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "Tisword = \"https://tisword.com/realtime/\"\n",
    "response = requests.get(Tisword) #티스워드 서버에 요청하고, 응답 받은 값을 변수에 저장\n",
    "\n",
    "soup = BeautifulSoup(response.text.decode('UTF-8','replace'), 'html.parser') #Data는 원하는 걸로 변경 가능\n",
    "soup.findAll('title')\n",
    "## 파싱: decode를 통해서 한글이 깨지는 현상을 해결\n",
    "## UTF-8을 통해서 수정\n",
    "# The way of use BeautifulSoup = BeautifulSoup(Data, a way of parsing)\n",
    "print(response.text[:500]) # url의 html 코드 문자열 500자까지 슬라이싱 \n",
    "print(type(BeautifulSoup(response.text, 'html.parser'))) #response.text라는 data를 html.parser라는 방식으로 parsing\n",
    "#BeautifulSoup는 어떤 통에다 데이터를 담아주는데, 통에는 다양한 칸막이들이 있어서 문자열을 집어넣으면 데이터를 하나하나 다 떼서 통에 가지런히 넣어줌.\n",
    "#자료형 확인하고 싶으면 type function 사용\n",
    "'''\n",
    "#print(response.url) ## 주소를 가져온다.\n",
    "#print(response.content) ## contents 를 가져온다.\n",
    "#print(response.encoding) ## encoding 방식를 가져온다.\n",
    "#print(response.headers) ## header를 가져온다.\n",
    "#print(response.json) ## json을 가져온다.\n",
    "#print(response.links) ## 링크들을 가져온다.\n",
    "#print(response.ok) ## 요청 허용 여부를 가져온다.\n",
    "## https://docs.python-requests.org/en/master/api/#requests.Response\n",
    "'''\n",
    "'''\n",
    "#file = open(\"Tisword.html\",\"w\",encoding = \"UTF-8\")\n",
    "#file.write(response.text) ## 잘 이해 안감\n",
    "#file.close()\n",
    "## 자신의 워크 스페이스에 Tisword.html이 생기게 된다.\n",
    "## 여기서 공통점을 찾아서 실시간 검색어를 찾아오도록 한다.\n",
    "## a 태그에 link_favorsch 클래스를 가지고 있다.\n",
    "\n",
    "'''\n",
    "'''\n",
    "#print(soup.title)\n",
    "#print(soup.title.string) #title에서 태그 빼고 문자열만 가져오기\n",
    "#print(soup.span) #html 코드에서 가장 상단의 span tag 가져오기\n",
    "#print(soup.findAll('span')) #모든 span tag 가져오기\n",
    "'''\n",
    "# html 문서에서 모든 div 태그 + 클래스를 가져오는 코드\n",
    "results = (soup.findAll('div','py-4 flex text-lg'))\n",
    "\n",
    "search_rank_file = open(\"rankresult.txt\",\"w\") # open(File, Mode) File 확장자는 원하는대로 하고, \n",
    "#모드는 r(ead), w(rite), a(ppend). read는 읽기 전용, write는 수정하면 변경 사항이 기존 사항 덮어쓰고, append는 기존 내용 보존한 후 덧붙이는 모드\n",
    "\n",
    "rank = 1\n",
    "\n",
    "print(datetime.today().strftime(\"%Y년 %m월 %d일의 실시간 검색어 순위입니다.\\n\"))\n",
    "\n",
    "for result in results:\n",
    "    search_rank_file.write(str(rank)+\"위:\"+result.get_text()+\"\\n\") # +말고 ,로 잇는건 안되나?\n",
    "    print(rank,'위: ',result.get_text(),'\\n') #태그들 안 가져오고 실검 텍스트만 가져오기#줄 바꿈 해서 출력해주기, 깔끔하게\n",
    "    rank += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b8de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}\n",
    "#네이버 같은 경우, 크롤링 봇 막아놓음. 그렇기에 나 봇 아니고 크롤링 한 번만 해갈게. 나 사람이야. 라는 구문임.\n",
    "url = \"https://datalab.naver.com/keyword/realtimeList.naver?age=20s\"\n",
    "response = requests.get(url, headers = headers) #요청할 때 사람인걸 알려주려고 씀.\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "rank = 1\n",
    "# span - item_title\n",
    "results = soup.findAll('span','item_title')\n",
    "\n",
    "print(response.text)\n",
    "\n",
    "search_rank_file = open(\"rankresult.txt\",\"a\")\n",
    "\n",
    "print(datetime.today().strftime(\"%Y년 %m월 %d일의 실시간 검색어 순위입니다.\\n\"))\n",
    "\n",
    "for result in results:\n",
    "    search_rank_file.write(str(rank)+\"위:\"+result.get_text()+\"\\n\")\n",
    "    print(rank,\"위 : \",result.get_text(),\"\\n\")\n",
    "    rank += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7469c9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 뉴스:성균관대-대만국립정치대,양교총장온라인명예박사학위상호수여식개최\n",
      "2번 뉴스:수학과김성연박사,2022년대한수학회학위논문상수상\n",
      "3번 뉴스:성균관대글로벌창업대학원,스테이정글과푸드테크창업생태계를위한MOU체결\n",
      "4번 뉴스:성균관대로스쿨법원로클럭최다임용\n",
      "5번 뉴스:성균관대,‘기술노벨상’수상자그라첼교수초청제1회SIEST포럼개최\n",
      "6번 뉴스:사회과학대학,해외저명대학교수초청시리즈세스슈월츠특강성료\n",
      "7번 뉴스:글로벌바이오메디컬공학과박천권교수,‘메디포스트신진과학자상’수상\n",
      "8번 뉴스:박상조회장공과대학발전기금1억원기부\n",
      "9번 뉴스:우리대학,3단계산학연협력선도대학선정\n",
      "10번 뉴스:윤용택성균관대총동창회장재선임\n"
     ]
    }
   ],
   "source": [
    "##성대신문 첫 페이지 기사 크롤링\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "url = 'https://www.skku.edu/skku/campus/skk_comm/news.do'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "html = response.text ## 텍스트를 가져온다.\n",
    "soup = BeautifulSoup(html, 'html.parser') ## html로 읽어와준다.\n",
    "title = soup.find_all(\"div\", class_='news_listCont') # div태그에 있는 클래스가 news_listCont를 가져온다.\n",
    "#find_all이 findAll 보다 new version. just google it.\n",
    "\n",
    "titles = []\n",
    "for x in title:\n",
    "\ttitles.append(re.sub(r\"[\\n\\t\\s]*\", \"\", x.find(\"a\").get_text())) \n",
    "## 읽어왔을 때 \\n, \\t, \\s가 존재 -> re.sub을 통해서 \"\"로 대체\n",
    "## a 테그를 찾은 이후에, 문자열로 바꾼다.\n",
    "## append를 통해서 리스트에 담는다.\n",
    "titles ## 리스트 형태로 저장 -> 뭔 소리지?\n",
    "\n",
    "for i in range(0, len(titles)):\n",
    "    print(str(i+1)+\"번 뉴스:\"+ titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7d6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HTML, CSS 속성을 이용해 가져오기\n",
    "## 이렇게 html 속성을 지정합니다.\n",
    "soup.find_all(attrs={'class':'footer-list', 'id':'footer-address-list'})\n",
    "\"\"\"\n",
    "[<ul class=\"footer-list\" id=\"footer-address-list\">\n",
    "<li class=\"footer-list-item\">사업자 등록번호 : 375-87-00088</li>\n",
    "<li class=\"footer-list-item\"><address>서울특별시 강남구 테헤란로4길 14 미림타워 14층</address></li>\n",
    "<li class=\"footer-list-item\"><a href=\"mailto:team@daangn.com\">team@daangn.com</a></li>\n",
    "</ul>]\n",
    "\"\"\"\n",
    "\n",
    "## css 속성을 통해서 가져옵니다.\n",
    "soup.select(\".card-region-name\")\n",
    "\n",
    "\"\"\"\n",
    "[<div class=\"card-region-name\">    \n",
    "        경기도 수원시 팔달구 인계동\n",
    "      </div>,\n",
    " <div class=\"card-region-name\">    \n",
    "        경기도 수원시 팔달구 화서동\n",
    "      </div>,\n",
    " <div class=\"card-region-name\">\n",
    "        서울 마포구 용강동\n",
    "      </div>,\n",
    " .\n",
    " .\n",
    " .\n",
    " <div class=\"card-region-name\">\n",
    "        서울 마포구 상암동\n",
    "      </div>,\n",
    " <div class=\"card-region-name\">\n",
    "        서울 성동구 상왕십리동\n",
    "      </div>,\n",
    " <div class=\"card-region-name\">\n",
    "        대구 북구 침산동\n",
    "      </div>]\n",
    "\"\"\"\n",
    "\n",
    "## id 앞에는 #을 사용합니다.\n",
    "soup.select(\"#hot-articles-go-download\")\n",
    "\n",
    "## 텍스트만 읽어오기, 클래스가 card-title인 것들의 텍스트 10개만 뽑아보기\n",
    "for x in range(0,10):\n",
    "    print(soup.select(\".card-title\")[x].get_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
